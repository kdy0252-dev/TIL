---
id: 대규모 트래픽 대응을 위한 커널 최적화 전략
started: 2026-01-14
tags:
  - ✅DONE
  - Linux
  - Optimization
  - Kernel
  - HighTraffic
group:
  - "[[Linux]]"
---
# 대규모 트래픽 대응을 위한 리눅스 커널 최적화 전략

## 0. 개요

본 문서는 단일 서버 인프라에서 초당 수십만 건 이상의 요청(RPS) 또는 수만 명 이상의 동시 연결자를 수용해야 하는 고성능 시스템 환경을 위한 **커널 레벨 최적화 가이드**이다. 리눅스 커널은 기본적으로 범용적인 사용성을 지향하므로, 하이엔드 트래픽 환경에서는 기본 설정값이 성능 병목 및 서비스 중단의 임계점으로 작용한다.

본 자산은 단순히 설정값을 나열하는 것을 넘어, **[커널 내부 동작 원리 - 장애 징후 탐지 - 정밀 튜닝 - 정량적 검증]** 의 프로세스를 표준화하여 본인 및 동료 기술진이 최적의 의사결정을 내릴 수 있도록 돕는 것을 목적으로 한다.

---

## 1. 네트워크 레이어 최적화 (L3/L4 TCP Stack)

네트워크 스택은 대규모 트래픽 처리 시 CPU 자원 소모가 가장 크고 장애가 빈번히 발생하는 영역이다.

### 1.1 TCP 연결 대기열 관리 (Backlog Architecture)

클라이언트의 요청이 애플리케이션에 도달하기 전, 커널은 두 단계의 큐(Queue)를 통해 연결을 관리한다. 이 큐가 포화될 경우 신규 요청은 유실(Drop)되며 접속 지연 현상이 발생한다.

#### 1.1.1 SYN Backlog (`net.ipv4.tcp_max_syn_backlog`)
- **기술적 정의**: TCP 3-Way Handshake 과정 중 클라이언트로부터 SYN을 받고 ACK를 대기하는 'Half-Open' 상태의 연결들이 머무는 큐이다.
- **장애 징후 (Symptoms)**:
  - `netstat -s | grep "SYNs to LISTEN sockets dropped"` 수치 증가.
  - 외부 모니터링 시 `Connection Timeout` 발생률 상승.
  - `dmesg` 상에서 `TCP: TCP: Possible SYN flooding on port ...` 메시지 확인 시 (백로그 포화로 인한 오탐 가능성).
- **최적화 전략**:
  - 하이엔드 트래픽 환경에서는 최소 `262144` 이상을 권장한다.
  - 메모리 오버헤드를 고려하더라도 현대 서버급 장비에서는 수십만 단위 할당이 성능상 이점이 크다.
- **연계 설정**:
  - `net.ipv4.tcp_syncookies = 1`: 백로그 포화 시에도 쿠키 방식을 통해 연결을 유지하는 안정 장치이다. 단, CPU 부하가 발생할 수 있음을 인지해야 한다.

#### 1.1.2 Listen Queue / Accept Queue (`net.core.somaxconn`)
- **기술적 정의**: Handshake가 완료된 연결들이 애플리케이션의 `accept()` 호출을 기다리는 대기열이다.
- **장애 징후 (Symptoms)**:
  - 서버 로직의 지연(Blocking I/O 등)으로 `accept()` 속도가 유입 속도보다 느릴 때 급격히 차오른다.
  - 클라이언트 측에서 `Connection Refused` 또는 급격한 응답 지연이 발생한다.
- **최적화 가이드**:
  - 시스템 전역 설정(`somaxconn`) 외에도 애플리케이션(Nginx, Tomcat, Netty 등) 내 별도의 `backlog` 파라미터를 반드시 동일 수치 이상으로 조정해야 한다.
  - 권장 수치: `65535` 혹은 그 이상 (OS 임계치 확인 필요).

### 1.2 소켓 자원 회수 및 로컬 포트 관리

#### 1.2.1 Ephemeral Port 확장 (`net.ipv4.ip_local_port_range`)
- **배경**: 클라이언트로서 외부 API 호출이나 DB 연결을 빈번히 수행할 때 사용되는 임시 포트가 고갈되는 현상이 발생한다.
- **설정 표준**: `1024 65535`
- **Rationale**: 시스템 예약 포트를 제외한 전체 가용 범위를 활용하여 포트 충돌 및 고갈 위험을 최소화한다.

#### 1.2.2 TIME_WAIT 최적화 (`net.ipv4.tcp_tw_reuse`)
- **기술적 정의**: 활발한 연결/해제 과정에서 산적하는 `TIME_WAIT` 상태 소켓을 신규 연결에 즉각 재사용하도록 허용한다.
- **필수 조건**: `net.ipv4.tcp_timestamps = 1` 활성화 시에만 정상 작동하며, 시간 순서가 보장되어야 패킷 혼선이 없다.
- **효과**: 불필요한 자원 점유 시간을 제거하고 포트 가용성을 극대화한다.

#### 1.2.3 FIN_WAIT_2 타임아웃 단축 (`net.ipv4.tcp_fin_timeout`)
- **설정**: 기본 60초 → `15~20초`
- **목적**: 비정상적인 종료 세션을 빠르게 정리하여 커널 메모리 및 FD 자원 낭비를 방지한다.

---

## 2. 파일 리소스 기술자 (File Descriptor) 관리

리눅스 아키텍처에서 소켓은 파일로 관리되므로, 시스템 및 프로세스 레벨의 오픈 파일 제한 상향은 고성능 서버의 필수 덕목이다.

### 2.1 시스템 전역 한계치 (`fs.file-max`)
- **정의**: 전체 운영체제 레이어에서 동시에 열 수 있는 파일 객체의 최대 수이다.
- **산정 방식**: 시스템 성능 및 메모리 가용량에 따라 수백만 단위(예: `2097152`)로 여유 있게 설정한다.

### 2.2 프로세스별 리소스 제한 (`ulimit` / `limits.conf`)
- **설정 주의사항**:
  - `Soft Limit`: 프로세스가 자체적으로 경고 없이 확장 가능한 범위.
  - `Hard Limit`: 커널이 강제하는 상한선.
- **운영 표준**:
  ```text
  * soft nofile 1,048,576
  * hard nofile 1,048,576
  ```
- **애플리케이션 연계**: systemd 서비스를 통해 실행되는 애플리케이션의 경우 `LimitNOFILE=...` 설정을 서비스 유닛 파일에 직접 명시해야 전역 설정의 누락을 방지할 수 있다.

---

## 3. 커널 메모리 및 데이터 전송 최적화 (Memory Management)

네트워크 인터페이스 카드(NIC)와 커널 스택 사이의 데이터 전송 효율을 극대화하기 위한 버퍼 튜닝 단계이다.

### 3.1 소켓 송수신 버퍼 최적화
트래픽 폭증 시 소켓 버퍼가 작으면 버퍼 오버플로우로 인해 패킷 드롭이 발생하고, 이는 곧 TCP 재전송(Retransmission) 증가와 성능 저하로 이어진다.

- **`net.core.rmem_max` / `net.core.wmem_max`**: 전역 수신/송신 최대 버퍼 크기. 고속 네트워크 장비 사용 시 `16MB(16777216)` 이상 권장.
- **`net.ipv4.tcp_rmem` / `net.ipv4.tcp_wmem`**: TCP 소켓별 [min, default, max] 크기 상세 조정.
  - Max 값은 `net.core.rmem_max`와 일치시키는 것이 일반적이다.
- **TCP Window Scaling**: 대용량 데이터 전송 시 윈도우 크기를 64KB 이상으로 확장하기 위해 반드시 활성화(`net.ipv4.tcp_window_scaling = 1`) 상태여야 한다.

### 3.2 가상 메모리 정책 (Swappiness & HugePages)

#### 3.2.1 Swappiness (`vm.swappiness`)
- **전략**: 고성능 서버에서는 스왑 영역 사용(Disk I/O 발생) 자체가 치명적인 지연을 유발한다.
- **권장값**: `10` 이하 (메모리 집약적인 DB 서버의 경우 `1`까지 고려 가능).
- **목적**: 물리 메모리가 충분함에도 불구하고 커널이 페이지 캐시 확보를 위해 응용 프로그램 메모리를 디스크로 스왑하는 행위를 차단한다.

#### 3.2.2 Huge Pages (`vm.nr_hugepages`)
- **적업 대상**: 수십 GB 이상의 메모리를 사용하는 Database(MySQL, Oracle, PostgreSQL) 또는 Redis와 같은 인메모리 시스템.
- **기대 효과**: 표준 4KB 페이지 대신 2MB 단위의 대형 페이지를 사용하여 메모리 주소 조회 시 발생하는 TLB(Translation Lookaside Buffer) 미스 및 CPU 사이클 낭비를 획기적으로 줄인다.

---

## 4. 커넥션 트래킹 및 보안 최적화 (Netfilter/Conntrack)

`iptables`, `nftables` 등을 사용하는 환경에서 가장 먼저 임계치에 도달하는 영역이다.

### 4.1 Conntrack Table 레이아웃 튜닝

#### 4.1.1 `net.netfilter.nf_conntrack_max`
- **현상**: 테이블 충만 시 `nf_conntrack: table full, dropping packet` 메시지와 함께 모든 신규 연결이 소멸한다.
- **최적화**: 동시 접속자 수의 2~4배 이상으로 넉넉히 설정(예: `1,048,576`).

#### 4.1.2 `net.netfilter.nf_conntrack_buckets`
- **원리**: 실제 커넥션 데이터가 해싱되어 저장되는 버킷 수이다.
- **공식**: `nf_conntrack_max / 4`를 기준으로 하되, 검색 부하를 줄이기 위해 소수(Prime number)나 2의 거듭제곱 근사치를 활용한다.

### 4.2 자원 회수 가속화 (Timeout Tuning)
- **`net.netfilter.nf_conntrack_tcp_timeout_established`**: 기본 5일(432,000s) → `1,200s (20분)`
- **`net.netfilter.nf_conntrack_tcp_timeout_close_wait`**: `60s` 이하
- **Rationale**: 비활성 상태이거나 이미 종료된 세션이 트래킹 테이블에 장기간 잔류하여 메모리를 점유하는 것을 방지한다.

---

## 5. CPU 스케줄링 및 인터럽트 튜닝 (Processing Efficiency)

트래픽 처리는 결국 CPU의 몫이다. 패킷 수신 인터럽트가 특정 CPU 0번에 몰리는 현상을 해결해야 한다.

### 5.1 IRQ 밸런싱 및 RSS (Receive Side Scaling)
- **RSS**: 하드웨어 레벨에서 다중 큐를 지원하는 NIC를 통해 패킷 처리를 여러 CPU 코어로 분산한다.
- **운영 가이드**: `irqbalance` 데몬의 상태를 확인하고, 특정 코어 쏠림이 확인될 경우 수동으로 `/proc/irq/[num]/smp_affinity`를 지정하여 코어별 부하를 균등화한다.

### 5.2 RPS / RFS (Software-based Steering)
- 하드웨어가 다중 큐를 충분히 지원하지 못할 경우, 커널 소프트웨어 레이어에서 수신 패킷을 다른 CPU 코어로 포워딩하여 부하를 분산한다.
- **설정 위치**: `/sys/class/net/[인터페이스]/queues/rx-[n]/rps_cpus`

---

## 6. 디스크 I/O 최적화 (Persistence Layer)

로그 기록 및 DB 트랜잭션 수용 성능을 높이기 위한 설정이다.

### 6.1 I/O Scheduler 선택 가이드
- **NVMe / SSD**: 복잡한 재정렬 알고리즘이 오히려 오버헤드가 되므로 `none` 또는 `mq-deadline` 사용을 권장한다.
- **HDD**: 대량의 쓰기가 발생하는 경우 `bfq` 또는 `deadline`이 유리할 수 있다.

### 6.2 Filesystem Mount Options
- **`noatime`**: 파일 열람 시마다 수정을 수행하는 '접근 시간 기록' 기능을 비활성화하여 메타데이터 갱신 오버헤드를 약 10~20% 절감한다.
- **`barrier=0`**: (주의 필요) 파일 시스템 정합성보다 성능이 극단적으로 중요한 로그성 저장을 수행할 때 사용 고려 가능.

---

## 7. 장애 대응 및 소급 적용 (Standard Operating Procedure)

최적화는 반드시 안정성이 담보된 상태에서 단계적으로 수행되어야 한다.

### 7.1 설정 적용 워크플로우 (SOP)
1.  **Baseline 측정**: 현재 `sysctl` 상태와 트래픽 지표(Latency, RPS, Error Rate)를 백업한다.
2.  **스테이징 검증**: 실제 운영과 유사한 부하 테스트 환경(nGrinder 등)에서 설정을 주입한다.
3.  **점진적 배포**: 카나리(Canary) 배포 방식을 통해 서버군 중 일부에만 우선 적용하여 24시간 이상 모니터링한다.
4.  **전역 적용**: 특이 사항이 없을 시 전체 클러스터에 배포하고 구성 관리 도구(Ansible, Terraform)를 통해 형상 관리 상태를 유지한다.

### 7.2 롤백 시나리오
- 예상치 못한 커널 패닉(Kernel Panic)이나 메모리 누수 발생 시 즉각적으로 기본 설정(`sysctl -p /etc/sysctl.conf.bak`)으로 복구할 수 있는 스크립트를 상비해야 한다.

---

## 8. 모니터링 대시보드 필수 항목 (Observability)

데이터 자산화의 가치는 지속적인 관찰에서 나온다. 다음 지표들을 Prometheus/Grafana 대시보드에 필수로 포함한다.

| 카테고리 | 핵심 지표 (Metric Labels) | 위험 신호 (Alert Threshold) |
| :--- | :--- | :--- |
| **Network** | `node_netstat_Tcp_Ext_ListenDrops` | 0 초과 시 즉시 대응 |
| **Network** | `node_sockstat_TCP_tw` | Ephemeral Range의 80% 근접 시 |
| **FD** | `node_filefd_allocated` | `fs.file-max`의 90% 상회 시 |
| **Memory** | `node_memory_SwapTotal - node_memory_SwapFree` | 0 초과 발생 시 (성능 저하 시작) |
| **Conntrack** | `node_nf_conntrack_entries` | Max 값의 80% 도달 시 |

---

## 9. 추신

본 지식 자산에 기술된 모든 수치는 '이론적 권장치'일 뿐이다. 실제 시스템 아키텍처(CPU 세대, NIC 드라이버 버전, 애플리케이션 프레임워크 특성 등)에 따라 최적의 수치는 달라질 수 있다. 

따라서 **데이터 기반의 반복적인 실험**만이 시스템의 진정한 임계치를 확장하는 유일한 길임을 명심해야 한다. 

---
## Reference
- **Official Docs**: [The Linux Kernel Archive - Documentation](https://www.kernel.org/doc/html/latest/)
- **Standard Guidelines**: [Cloudflare Engineering - How we built a 100Gbps network](https://blog.cloudflare.com/how-we-built-a-100gbps-network-on-linux-part-1/)
- **Performance Analysis**: [Brendan Gregg's Blog - Linux Performance](https://www.brendangregg.com/linuxperf.html)
- **Networking Deep Dive**: [Packagecloud - Monitoring and Tuning the Linux Networking Stack](https://blog.packagecloud.io/monitoring-tuning-linux-networking-stack-receiving-data/)