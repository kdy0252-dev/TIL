---
id: 6. Offline 환경에서 Grafana Stack 설치방법
started: 2025-04-08
tags:
  - ✅DONE
  - helm
group:
  - "[[K8S]]"
---
# 6. Offline 환경에서 Grafana Stack 설치방법
인터넷이 차단된(에어갭) 쿠버네티스 환경에서 Helm 차트를 사용해 Grafana를 설치하려면 Helm 차트와 Grafana 컨테이너 이미지를 모두 로컬에 준비해야 합니다. 전체적인 워크플로우는 다음과 같습니다:
1. **인터넷이 연결된 머신에서**
    - Grafana Helm 차트(및 의존성) 다운로드
    - Grafana 도커 이미지를 풀(pull)해서 tarball로 저장
2. **오프라인 환경으로** 위 아티팩트들을 전송(USB나 사설 파일 서버 등)
3. **에어갭 클러스터에서**
    - 노드에 도커 이미지 로드
    - (선택) ChartMuseum 같은 로컬 Helm 저장소에 차트 호스팅 또는 차트 디렉토리 직접 사용
    - `helm install` 시 로컬 차트를 가리키도록 설치
---
## 1. Helm 차트 및 의존성 다운로드
인터넷이 연결된 머신에서:
```shell title="Download grafana chart"
# Grafana 공식 Helm 저장소 등록 및 업데이트
helm repo add grafana https://grafana.github.io/helm-charts
helm repo update

# 특정 버전(예: 6.34.0) 차트 풀(pull) 및 언타르
mkdir -p grafana-chart
helm pull grafana/grafana \
  --version 6.34.0 \
  --untar \
  --untardir ./grafana-chart

# 차트 의존성 가져오기
cd grafana-chart/grafana
helm dependency update
cd ../../

# (선택) 하나의 .tgz 패키지로 묶기
helm package grafana-chart/grafana
# → grafana-6.34.0.tgz 생성
```
이제 아래 둘 중 하나가 준비됩니다:
- `grafana-chart/grafana/` 디렉토리 (Chart.yaml, values.yaml, charts/ 포함)
- 또는 `grafana-6.34.0.tgz` 패키지
---
## 2. Grafana 도커 이미지 저장
같은 머신에서:
```shell title="이미지 Pull"
# 이미지 풀
docker pull grafana/grafana:9.5.7

# tarball로 저장
docker save grafana/grafana:9.5.7 -o grafana_9.5.7.tar
```
---
## 3. 아티팩트 전송
USB나 사설 네트워크 파일 서버 등을 이용해 오프라인 환경으로 다음 파일/디렉토리 복사:
- `grafana-chart/grafana/` 디렉토리 **또는** `grafana-6.34.0.tgz`
- `grafana_9.5.7.tar`
---
## 4. 에어갭 클러스터 준비
### a) 도커 이미지 로드
각 노드(또는 프라이빗 레지스트리)에서:
`docker load -i /path/to/grafana_9.5.7.tar`
> [!INFO] 프라이빗 레지스트리를 운영 중이라면 `docker push` 후 Helm values에서 이미지 레포를 오버라이드할 수도 있습니다.
### b) (선택) 로컬 ChartMuseum 설정
로컬 Helm 저장소로 사용하려면:
1. ChartMuseum 배포 (ChartMuseum 차트도 오프라인으로 가져와야 함)
2. `grafana-6.34.0.tgz` 업로드:
    `curl --data-binary "@grafana-6.34.0.tgz" http://<chartmuseum-service>/api/charts`
3. Helm에 로컬 저장소 등록:
    `helm repo add local-charts http://<chartmuseum-service> helm repo update`
---
## 5. Helm으로 Grafana 설치
세 가지 방법 중 선택:
### A) 언팩된 차트 직접 사용
```shell
helm install grafana \
  /path/to/grafana-chart/grafana \
  --namespace monitoring --create-namespace \
  --set image.repository=grafana/grafana \
  --set image.tag=9.5.7 \
  --set rbac.pspEnabled=false \
  --set testFramework.enabled=false
```
### B) 패키지된 `.tgz` 사용
```shell
helm install grafana \
  ./grafana-6.34.0.tgz \
  --namespace grafana --create-namespace \
  --set image.repository=docker.io/grafana/grafana \
  --set image.tag=9.5.7 \
  --set rbac.pspEnabled=false \
  --set testFramework.enabled=false
```
### C) 로컬 ChartMuseum 저장소 사용
```shell
helm install grafana \
  local-charts/grafana \
  --version 6.34.0 \
  --namespace monitoring --create-namespace \
  --set image.repository=grafana/grafana \
  --set image.tag=9.5.7 \
  --set rbac.pspEnabled=false \
  --set testFramework.enabled=false

```
---
## 6. 설치 후 확인
1. **파드 상태 확인**:
    `kubectl get pods -n monitoring`
2. **포트 포워딩**:
    `kubectl port-forward svc/grafana 3000:80 -n monitoring`
3. 브라우저에서 `http://localhost:3000` 접속  
    초기 계정: `admin` / `admin` (로그인 후 비밀번호 변경)

```shell
NAMESPACE: grafana
STATUS: deployed
REVISION: 1
TEST SUITE: None
NOTES:
1. Get your 'admin' user password by running:

   kubectl get secret --namespace grafana grafana -o jsonpath="{.data.admin-password}" | base64 --decode ; echo

2. The Grafana server can be accessed via port 80 on the following DNS name from within your cluster:

   grafana.grafana.svc.cluster.local

   Get the Grafana URL to visit by running these commands in the same shell:

     export POD_NAME=$(kubectl get pods --namespace grafana -l "app.kubernetes.io/name=grafana,app.kubernetes.io/instance=grafana" -o jsonpath="{.items[0].metadata.name}")
     kubectl --namespace grafana port-forward $POD_NAME 3000

3. Login with the password from step 1 and the username: admin
#################################################################################
######   WARNING: Persistence is disabled!!! You will lose your data when   #####
######            the Grafana pod is terminated.                            #####
#################################################################################
```

---
## 접속 방법
VM의 IP(192.168.77.11)와 Grafana 서비스의 ClusterIP(172.16.235.192)는 서로 다른 네트워크에 있기 때문에, 바로 브라우저에서 172.16.235.192:80 으로는 접근할 수 없습니다. 외부(호스트)에서 Grafana에 접속하려면 크게 두 가지 방법이 있습니다.

### 1. kubectl port‑forward 사용하기

가장 간단한 방법으로, Grafana Pod(또는 Service)에 로컬 머신의 포트를 터널링합니다.
```shell
# grafana 네임스페이스의 Service를 192.168.77.11(모든 인터페이스)에 바인딩
kubectl port-forward --address 0.0.0.0 svc/grafana 3000:80 -n grafana
```

아래와 같이 브라우저에서 접속하면 된다.
```
http://192.168.77.11:3000
```

### 2. Service 타입을 NodePort 또는 LoadBalancer로 변경하기
#### A) NodePort
1. Helm 설치 시 또는 `helm upgrade` 로 values에 다음을 추가합니다:
```yaml
service:
  type: NodePort
  port: 80
  nodePort: 32000    # 30000~32767 사이의 사용 가능한 포트
```
예시
```shell
helm upgrade grafana ./grafana-6.34.0.tgz \
  --namespace grafana \
  --set service.type=NodePort \
  --set service.nodePort=32000 \
  --set image.repository=docker.io/grafana/grafana \
  --set image.tag=9.5.7 \
  --set rbac.pspEnabled=false \
  --set testFramework.enabled=false
  --reuse-values
```
그 후 호스트(192.168.77.11)에서:
```
http://192.168.77.11:32000
```

### B) LoadBalancer (MetalLB 등)
클러스터에 MetalLB 같은 On‑Prem LB가 설치돼 있으면, `service.type=LoadBalancer` 만 설정해도 외부 IP가 할당됩니다.
```
helm upgrade grafana ./grafana-6.34.0.tgz \
  --namespace grafana \
  --set service.type=LoadBalancer \
  --reuse-values
```
할당된 EXTERNAL‑IP 를 확인한 뒤 그 주소:80 으로 접속하세요.

---
### 팁 & 문제 해결
- **의존성 누락?** `charts/` 디렉토리가 `Chart.yaml` 옆에 있는지 확인하세요.
- **이미지 풀 오류?** `values.yaml`에 설정된 이미지 이름/태그가 로드한 것과 일치하는지 확인하세요.
- **프라이빗 레지스트리 사용 시** 레포지토리 주소를 예:
    `image:   repository: my-registry.local:5000/grafana/grafana   tag: 9.5.7`
- **업데이트 자동화**: Grafana Helm 저장소 전체를 OCI 레지스트리로 미러링한 뒤 `helm chart pull` 및 `helm chart export`로 관리할 수 있습니다.

아래와 같이 인터넷이 연결되어 있지 않아도 접속 할 수 있음을 확인 할 수 있다.

![[Pasted image 20250408103106.png]]

# 로그 저장 설정

Grafana Loki 자체는 “로그를 수집해서 DB에 넣는” 역할을 하며, 실제 로그 데이터(Chunk)와 인덱스(Index) 파일은 아래와 같이 구성된 스토리지 경로에 저장됩니다. Kubernetes 환경에서는 이 경로를 PersistentVolumeClaim(PVC)에 마운트하여 영속화하는 것이 일반적입니다.

---
## 1. 기본 저장 경로 (Filesystem 모드)
Loki의 `config.yaml` 에서 `storage_config.filesystem` 항목으로 지정한 디렉토리가 바로 로그 파일이 저장되는 위치입니다.  
예를 들어, Helm 차트의 기본값 중 일부를 보면:
```yaml
storage_config:
  boltdb_shipper:
    active_index_directory: /data/loki/index
    shared_store: filesystem
  filesystem:
    directory: /data/loki/chunks
```
- **Chunk 파일**: `/data/loki/chunks`
- **Index 파일**: `/data/loki/index`
이 두 디렉토리 안에 각각 로그 청크와 인덱스 메타데이터가 들어갑니다.
---
## 2. Kubernetes에서의 PVC 마운트
Loki를 StatefulSet(또는 Deployment)으로 배포할 때, 위 경로(`/data/loki`)를 PVC에 마운트하여 사용합니다. 예시 YAML 스니펫:
```yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: loki
spec:
  serviceName: loki
  replicas: 1
  selector:
    matchLabels:
      app: loki
  template:
    metadata:
      labels:
        app: loki
    spec:
      containers:
      - name: loki
        image: grafana/loki:2.8.2
        args:
          - -config.file=/etc/loki/config.yaml
        volumeMounts:
          - name: loki-storage
            mountPath: /data/loki
  volumeClaimTemplates:
  - metadata:
      name: loki-storage
    spec:
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: 10Gi
위 예에서:

PVC 이름: loki-storage

마운트 경로: /data/loki

실제 물리 스토리지: 클러스터의 PV (예: AWS EBS, GCE PD, NFS 등)

따라서 /data/loki/chunks, /data/loki/index 폴더가 PVC에 영속적으로 저장됩니다.

3. Object Storage 모드 (S3, GCS 등)
만약 S3나 GCS 같은 오브젝트 스토리지를 사용하도록 설정했다면, storage_config 항목이 다음처럼 바뀝니다:

yaml
복사
storage_config:
  boltdb_shipper:
    active_index_directory: /data/loki/index
    shared_store: s3
  aws:
    s3: s3://<버킷명>/loki/chunks
```
위 예에서:
- **PVC 이름**: `loki-storage`
- **마운트 경로**: `/data/loki`
- **실제 물리 스토리지**: 클러스터의 PV (예: AWS EBS, GCE PD, NFS 등)
따라서 `/data/loki/chunks`, `/data/loki/index` 폴더가 PVC에 영속적으로 저장됩니다.
---
## 3. Object Storage 모드 (S3, GCS 등)
만약 S3나 GCS 같은 오브젝트 스토리지를 사용하도록 설정했다면, `storage_config` 항목이 다음처럼 바뀝니다:
```yaml
storage_config:
  boltdb_shipper:
    active_index_directory: /data/loki/index
    shared_store: s3
  aws:
    s3: s3://<버킷명>/loki/chunks
```
- **Chunk**: S3 버킷의 `loki/chunks/` 경로
- **Index**: 로컬 `/data/loki/index` 에 저장 (BoltDB Shipper 사용 시)
이 경우 파일 시스템에는 인덱스만 남고, 실제 로그 청크는 S3로 업로드되어 저장됩니다.
---
## 4. 요약
1. **Filesystem 모드**
    - 디폴트 경로: `/data/loki/chunks`, `/data/loki/index`
    - Kubernetes에서는 PVC → PV에 마운트
2. **Object Storage 모드**
    - Chunk 파일: S3/GCS/Azure Blob
    - Index 파일: 로컬 BoltDB 디렉토리 (PVC)
3. **Dev 모드(샘플)**
    - 단일 바이너리 실행 시 기본 경로: `/tmp/loki`

따라서 “파일이 어디에 있느냐”는 Loki 설정(`storage_config`)과 Kubernetes에서 마운트한 볼륨에 달려 있으며, 일반적으로는 위 예시의 PVC 마운트 경로(`/data/loki`) 하위에 저장된다고 보시면 됩니다.

# Reference
